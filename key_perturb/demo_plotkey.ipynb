{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## GiLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "model_name = 'gpt2-large'\n",
    "beams = 20\n",
    "max_new_tokens = 10\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2, 3\"\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight\n",
      "transformer.wpe.weight\n",
      "transformer.h.0.ln_1.weight\n",
      "transformer.h.0.ln_1.bias\n",
      "transformer.h.0.attn.c_attn.weight\n",
      "transformer.h.0.attn.c_attn.bias\n",
      "transformer.h.0.attn.c_proj.weight\n",
      "transformer.h.0.attn.c_proj.bias\n",
      "transformer.h.0.ln_2.weight\n",
      "transformer.h.0.ln_2.bias\n",
      "transformer.h.0.mlp.c_fc.weight\n",
      "transformer.h.0.mlp.c_fc.bias\n",
      "transformer.h.0.mlp.c_proj.weight\n",
      "transformer.h.0.mlp.c_proj.bias\n",
      "transformer.h.1.ln_1.weight\n",
      "transformer.h.1.ln_1.bias\n",
      "transformer.h.1.attn.c_attn.weight\n",
      "transformer.h.1.attn.c_attn.bias\n",
      "transformer.h.1.attn.c_proj.weight\n",
      "transformer.h.1.attn.c_proj.bias\n",
      "transformer.h.1.ln_2.weight\n",
      "transformer.h.1.ln_2.bias\n",
      "transformer.h.1.mlp.c_fc.weight\n",
      "transformer.h.1.mlp.c_fc.bias\n",
      "transformer.h.1.mlp.c_proj.weight\n",
      "transformer.h.1.mlp.c_proj.bias\n",
      "transformer.h.2.ln_1.weight\n",
      "transformer.h.2.ln_1.bias\n",
      "transformer.h.2.attn.c_attn.weight\n",
      "transformer.h.2.attn.c_attn.bias\n",
      "transformer.h.2.attn.c_proj.weight\n",
      "transformer.h.2.attn.c_proj.bias\n",
      "transformer.h.2.ln_2.weight\n",
      "transformer.h.2.ln_2.bias\n",
      "transformer.h.2.mlp.c_fc.weight\n",
      "transformer.h.2.mlp.c_fc.bias\n",
      "transformer.h.2.mlp.c_proj.weight\n",
      "transformer.h.2.mlp.c_proj.bias\n",
      "transformer.h.3.ln_1.weight\n",
      "transformer.h.3.ln_1.bias\n",
      "transformer.h.3.attn.c_attn.weight\n",
      "transformer.h.3.attn.c_attn.bias\n",
      "transformer.h.3.attn.c_proj.weight\n",
      "transformer.h.3.attn.c_proj.bias\n",
      "transformer.h.3.ln_2.weight\n",
      "transformer.h.3.ln_2.bias\n",
      "transformer.h.3.mlp.c_fc.weight\n",
      "transformer.h.3.mlp.c_fc.bias\n",
      "transformer.h.3.mlp.c_proj.weight\n",
      "transformer.h.3.mlp.c_proj.bias\n",
      "transformer.h.4.ln_1.weight\n",
      "transformer.h.4.ln_1.bias\n",
      "transformer.h.4.attn.c_attn.weight\n",
      "transformer.h.4.attn.c_attn.bias\n",
      "transformer.h.4.attn.c_proj.weight\n",
      "transformer.h.4.attn.c_proj.bias\n",
      "transformer.h.4.ln_2.weight\n",
      "transformer.h.4.ln_2.bias\n",
      "transformer.h.4.mlp.c_fc.weight\n",
      "transformer.h.4.mlp.c_fc.bias\n",
      "transformer.h.4.mlp.c_proj.weight\n",
      "transformer.h.4.mlp.c_proj.bias\n",
      "transformer.h.5.ln_1.weight\n",
      "transformer.h.5.ln_1.bias\n",
      "transformer.h.5.attn.c_attn.weight\n",
      "transformer.h.5.attn.c_attn.bias\n",
      "transformer.h.5.attn.c_proj.weight\n",
      "transformer.h.5.attn.c_proj.bias\n",
      "transformer.h.5.ln_2.weight\n",
      "transformer.h.5.ln_2.bias\n",
      "transformer.h.5.mlp.c_fc.weight\n",
      "transformer.h.5.mlp.c_fc.bias\n",
      "transformer.h.5.mlp.c_proj.weight\n",
      "transformer.h.5.mlp.c_proj.bias\n",
      "transformer.h.6.ln_1.weight\n",
      "transformer.h.6.ln_1.bias\n",
      "transformer.h.6.attn.c_attn.weight\n",
      "transformer.h.6.attn.c_attn.bias\n",
      "transformer.h.6.attn.c_proj.weight\n",
      "transformer.h.6.attn.c_proj.bias\n",
      "transformer.h.6.ln_2.weight\n",
      "transformer.h.6.ln_2.bias\n",
      "transformer.h.6.mlp.c_fc.weight\n",
      "transformer.h.6.mlp.c_fc.bias\n",
      "transformer.h.6.mlp.c_proj.weight\n",
      "transformer.h.6.mlp.c_proj.bias\n",
      "transformer.h.7.ln_1.weight\n",
      "transformer.h.7.ln_1.bias\n",
      "transformer.h.7.attn.c_attn.weight\n",
      "transformer.h.7.attn.c_attn.bias\n",
      "transformer.h.7.attn.c_proj.weight\n",
      "transformer.h.7.attn.c_proj.bias\n",
      "transformer.h.7.ln_2.weight\n",
      "transformer.h.7.ln_2.bias\n",
      "transformer.h.7.mlp.c_fc.weight\n",
      "transformer.h.7.mlp.c_fc.bias\n",
      "transformer.h.7.mlp.c_proj.weight\n",
      "transformer.h.7.mlp.c_proj.bias\n",
      "transformer.h.8.ln_1.weight\n",
      "transformer.h.8.ln_1.bias\n",
      "transformer.h.8.attn.c_attn.weight\n",
      "transformer.h.8.attn.c_attn.bias\n",
      "transformer.h.8.attn.c_proj.weight\n",
      "transformer.h.8.attn.c_proj.bias\n",
      "transformer.h.8.ln_2.weight\n",
      "transformer.h.8.ln_2.bias\n",
      "transformer.h.8.mlp.c_fc.weight\n",
      "transformer.h.8.mlp.c_fc.bias\n",
      "transformer.h.8.mlp.c_proj.weight\n",
      "transformer.h.8.mlp.c_proj.bias\n",
      "transformer.h.9.ln_1.weight\n",
      "transformer.h.9.ln_1.bias\n",
      "transformer.h.9.attn.c_attn.weight\n",
      "transformer.h.9.attn.c_attn.bias\n",
      "transformer.h.9.attn.c_proj.weight\n",
      "transformer.h.9.attn.c_proj.bias\n",
      "transformer.h.9.ln_2.weight\n",
      "transformer.h.9.ln_2.bias\n",
      "transformer.h.9.mlp.c_fc.weight\n",
      "transformer.h.9.mlp.c_fc.bias\n",
      "transformer.h.9.mlp.c_proj.weight\n",
      "transformer.h.9.mlp.c_proj.bias\n",
      "transformer.h.10.ln_1.weight\n",
      "transformer.h.10.ln_1.bias\n",
      "transformer.h.10.attn.c_attn.weight\n",
      "transformer.h.10.attn.c_attn.bias\n",
      "transformer.h.10.attn.c_proj.weight\n",
      "transformer.h.10.attn.c_proj.bias\n",
      "transformer.h.10.ln_2.weight\n",
      "transformer.h.10.ln_2.bias\n",
      "transformer.h.10.mlp.c_fc.weight\n",
      "transformer.h.10.mlp.c_fc.bias\n",
      "transformer.h.10.mlp.c_proj.weight\n",
      "transformer.h.10.mlp.c_proj.bias\n",
      "transformer.h.11.ln_1.weight\n",
      "transformer.h.11.ln_1.bias\n",
      "transformer.h.11.attn.c_attn.weight\n",
      "transformer.h.11.attn.c_attn.bias\n",
      "transformer.h.11.attn.c_proj.weight\n",
      "transformer.h.11.attn.c_proj.bias\n",
      "transformer.h.11.ln_2.weight\n",
      "transformer.h.11.ln_2.bias\n",
      "transformer.h.11.mlp.c_fc.weight\n",
      "transformer.h.11.mlp.c_fc.bias\n",
      "transformer.h.11.mlp.c_proj.weight\n",
      "transformer.h.11.mlp.c_proj.bias\n",
      "transformer.h.12.ln_1.weight\n",
      "transformer.h.12.ln_1.bias\n",
      "transformer.h.12.attn.c_attn.weight\n",
      "transformer.h.12.attn.c_attn.bias\n",
      "transformer.h.12.attn.c_proj.weight\n",
      "transformer.h.12.attn.c_proj.bias\n",
      "transformer.h.12.ln_2.weight\n",
      "transformer.h.12.ln_2.bias\n",
      "transformer.h.12.mlp.c_fc.weight\n",
      "transformer.h.12.mlp.c_fc.bias\n",
      "transformer.h.12.mlp.c_proj.weight\n",
      "transformer.h.12.mlp.c_proj.bias\n",
      "transformer.h.13.ln_1.weight\n",
      "transformer.h.13.ln_1.bias\n",
      "transformer.h.13.attn.c_attn.weight\n",
      "transformer.h.13.attn.c_attn.bias\n",
      "transformer.h.13.attn.c_proj.weight\n",
      "transformer.h.13.attn.c_proj.bias\n",
      "transformer.h.13.ln_2.weight\n",
      "transformer.h.13.ln_2.bias\n",
      "transformer.h.13.mlp.c_fc.weight\n",
      "transformer.h.13.mlp.c_fc.bias\n",
      "transformer.h.13.mlp.c_proj.weight\n",
      "transformer.h.13.mlp.c_proj.bias\n",
      "transformer.h.14.ln_1.weight\n",
      "transformer.h.14.ln_1.bias\n",
      "transformer.h.14.attn.c_attn.weight\n",
      "transformer.h.14.attn.c_attn.bias\n",
      "transformer.h.14.attn.c_proj.weight\n",
      "transformer.h.14.attn.c_proj.bias\n",
      "transformer.h.14.ln_2.weight\n",
      "transformer.h.14.ln_2.bias\n",
      "transformer.h.14.mlp.c_fc.weight\n",
      "transformer.h.14.mlp.c_fc.bias\n",
      "transformer.h.14.mlp.c_proj.weight\n",
      "transformer.h.14.mlp.c_proj.bias\n",
      "transformer.h.15.ln_1.weight\n",
      "transformer.h.15.ln_1.bias\n",
      "transformer.h.15.attn.c_attn.weight\n",
      "transformer.h.15.attn.c_attn.bias\n",
      "transformer.h.15.attn.c_proj.weight\n",
      "transformer.h.15.attn.c_proj.bias\n",
      "transformer.h.15.ln_2.weight\n",
      "transformer.h.15.ln_2.bias\n",
      "transformer.h.15.mlp.c_fc.weight\n",
      "transformer.h.15.mlp.c_fc.bias\n",
      "transformer.h.15.mlp.c_proj.weight\n",
      "transformer.h.15.mlp.c_proj.bias\n",
      "transformer.h.16.ln_1.weight\n",
      "transformer.h.16.ln_1.bias\n",
      "transformer.h.16.attn.c_attn.weight\n",
      "transformer.h.16.attn.c_attn.bias\n",
      "transformer.h.16.attn.c_proj.weight\n",
      "transformer.h.16.attn.c_proj.bias\n",
      "transformer.h.16.ln_2.weight\n",
      "transformer.h.16.ln_2.bias\n",
      "transformer.h.16.mlp.c_fc.weight\n",
      "transformer.h.16.mlp.c_fc.bias\n",
      "transformer.h.16.mlp.c_proj.weight\n",
      "transformer.h.16.mlp.c_proj.bias\n",
      "transformer.h.17.ln_1.weight\n",
      "transformer.h.17.ln_1.bias\n",
      "transformer.h.17.attn.c_attn.weight\n",
      "transformer.h.17.attn.c_attn.bias\n",
      "transformer.h.17.attn.c_proj.weight\n",
      "transformer.h.17.attn.c_proj.bias\n",
      "transformer.h.17.ln_2.weight\n",
      "transformer.h.17.ln_2.bias\n",
      "transformer.h.17.mlp.c_fc.weight\n",
      "transformer.h.17.mlp.c_fc.bias\n",
      "transformer.h.17.mlp.c_proj.weight\n",
      "transformer.h.17.mlp.c_proj.bias\n",
      "transformer.h.18.ln_1.weight\n",
      "transformer.h.18.ln_1.bias\n",
      "transformer.h.18.attn.c_attn.weight\n",
      "transformer.h.18.attn.c_attn.bias\n",
      "transformer.h.18.attn.c_proj.weight\n",
      "transformer.h.18.attn.c_proj.bias\n",
      "transformer.h.18.ln_2.weight\n",
      "transformer.h.18.ln_2.bias\n",
      "transformer.h.18.mlp.c_fc.weight\n",
      "transformer.h.18.mlp.c_fc.bias\n",
      "transformer.h.18.mlp.c_proj.weight\n",
      "transformer.h.18.mlp.c_proj.bias\n",
      "transformer.h.19.ln_1.weight\n",
      "transformer.h.19.ln_1.bias\n",
      "transformer.h.19.attn.c_attn.weight\n",
      "transformer.h.19.attn.c_attn.bias\n",
      "transformer.h.19.attn.c_proj.weight\n",
      "transformer.h.19.attn.c_proj.bias\n",
      "transformer.h.19.ln_2.weight\n",
      "transformer.h.19.ln_2.bias\n",
      "transformer.h.19.mlp.c_fc.weight\n",
      "transformer.h.19.mlp.c_fc.bias\n",
      "transformer.h.19.mlp.c_proj.weight\n",
      "transformer.h.19.mlp.c_proj.bias\n",
      "transformer.h.20.ln_1.weight\n",
      "transformer.h.20.ln_1.bias\n",
      "transformer.h.20.attn.c_attn.weight\n",
      "transformer.h.20.attn.c_attn.bias\n",
      "transformer.h.20.attn.c_proj.weight\n",
      "transformer.h.20.attn.c_proj.bias\n",
      "transformer.h.20.ln_2.weight\n",
      "transformer.h.20.ln_2.bias\n",
      "transformer.h.20.mlp.c_fc.weight\n",
      "transformer.h.20.mlp.c_fc.bias\n",
      "transformer.h.20.mlp.c_proj.weight\n",
      "transformer.h.20.mlp.c_proj.bias\n",
      "transformer.h.21.ln_1.weight\n",
      "transformer.h.21.ln_1.bias\n",
      "transformer.h.21.attn.c_attn.weight\n",
      "transformer.h.21.attn.c_attn.bias\n",
      "transformer.h.21.attn.c_proj.weight\n",
      "transformer.h.21.attn.c_proj.bias\n",
      "transformer.h.21.ln_2.weight\n",
      "transformer.h.21.ln_2.bias\n",
      "transformer.h.21.mlp.c_fc.weight\n",
      "transformer.h.21.mlp.c_fc.bias\n",
      "transformer.h.21.mlp.c_proj.weight\n",
      "transformer.h.21.mlp.c_proj.bias\n",
      "transformer.h.22.ln_1.weight\n",
      "transformer.h.22.ln_1.bias\n",
      "transformer.h.22.attn.c_attn.weight\n",
      "transformer.h.22.attn.c_attn.bias\n",
      "transformer.h.22.attn.c_proj.weight\n",
      "transformer.h.22.attn.c_proj.bias\n",
      "transformer.h.22.ln_2.weight\n",
      "transformer.h.22.ln_2.bias\n",
      "transformer.h.22.mlp.c_fc.weight\n",
      "transformer.h.22.mlp.c_fc.bias\n",
      "transformer.h.22.mlp.c_proj.weight\n",
      "transformer.h.22.mlp.c_proj.bias\n",
      "transformer.h.23.ln_1.weight\n",
      "transformer.h.23.ln_1.bias\n",
      "transformer.h.23.attn.c_attn.weight\n",
      "transformer.h.23.attn.c_attn.bias\n",
      "transformer.h.23.attn.c_proj.weight\n",
      "transformer.h.23.attn.c_proj.bias\n",
      "transformer.h.23.ln_2.weight\n",
      "transformer.h.23.ln_2.bias\n",
      "transformer.h.23.mlp.c_fc.weight\n",
      "transformer.h.23.mlp.c_fc.bias\n",
      "transformer.h.23.mlp.c_proj.weight\n",
      "transformer.h.23.mlp.c_proj.bias\n",
      "transformer.ln_f.weight\n",
      "transformer.ln_f.bias\n",
      "lm_head.weight\n"
     ]
    }
   ],
   "source": [
    "from utils import load_model, get_template\n",
    "model, tokenizer, block_name, embedding_name, embed_token_name, _, _ = load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpreter import Interpreter\n",
    "interpreter = Interpreter(model, block_name, embed_token_name, embed_token_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'token_index': 0, 'optimal_transport': tensor(0.4701, device='cuda:0', dtype=torch.float64)}, {'token_index': 1, 'optimal_transport': tensor(0.2135, device='cuda:0', dtype=torch.float64)}, {'token_index': 2, 'optimal_transport': tensor(0.2023, device='cuda:0', dtype=torch.float64)}, {'token_index': 3, 'optimal_transport': tensor(0.2421, device='cuda:0', dtype=torch.float64)}, {'token_index': 4, 'optimal_transport': tensor(0.1625, device='cuda:0', dtype=torch.float64)}, {'token_index': 5, 'optimal_transport': tensor(0.0941, device='cuda:0', dtype=torch.float64)}, {'token_index': 6, 'optimal_transport': tensor(0.0822, device='cuda:0', dtype=torch.float64)}, {'token_index': 7, 'optimal_transport': tensor(0.3652, device='cuda:0', dtype=torch.float64)}, {'token_index': 8, 'optimal_transport': tensor(0.0760, device='cuda:0', dtype=torch.float64)}, {'token_index': 9, 'optimal_transport': tensor(0.1068, device='cuda:0', dtype=torch.float64)}, {'token_index': 10, 'optimal_transport': tensor(0.0801, device='cuda:0', dtype=torch.float64)}, {'token_index': 11, 'optimal_transport': tensor(0.1187, device='cuda:0', dtype=torch.float64)}, {'token_index': 12, 'optimal_transport': tensor(0.2675, device='cuda:0', dtype=torch.float64)}, {'token_index': 13, 'optimal_transport': tensor(0.1584, device='cuda:0', dtype=torch.float64)}, {'token_index': 14, 'optimal_transport': tensor(0.0425, device='cuda:0', dtype=torch.float64)}, {'token_index': 15, 'optimal_transport': tensor(0.4665, device='cuda:0', dtype=torch.float64)}, {'token_index': 16, 'optimal_transport': tensor(0.2370, device='cuda:0', dtype=torch.float64)}, {'token_index': 17, 'optimal_transport': tensor(0.6317, device='cuda:0', dtype=torch.float64)}]\n",
      "tensor([0.0016, 0.0009, 0.0005, 0.0004, 0.0004, 0.0003, 0.0002, 0.0002, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0001, 0.0001,\n",
      "        0.0001, 0.0001], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from utils import load_model, get_template\n",
    "template = get_template(model_name)\n",
    "\n",
    "beams = 20\n",
    "max_new_tokens = 15\n",
    "\n",
    "query = \"The BRW Rich 200, 2014 is the 31st annual survey of the wealthiest people resident\"\n",
    "input_text = f\"{template['prefix']}{query.strip()}{template['postfix']}\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "inputs.to(device)\n",
    "attributions, probs_sequences = interpreter.interpret_ours(inputs.input_ids, beams, max_new_tokens, \"optimal_transport\")\n",
    "print(attributions)\n",
    "print(probs_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import HTML\n",
    "import os\n",
    "\n",
    "def show_heatmap_on_text(text, text_encoding, R_text, output_html=\"heatmap_visualization.html\"):\n",
    "    # Normalize relevance scores\n",
    "    text_scores = R_text / R_text.sum()\n",
    "    text_scores = text_scores.flatten()\n",
    "    \n",
    "    # Tokenize and decode the text\n",
    "    text_tokens = tokenizer.encode(text)\n",
    "    text_tokens_decoded = [tokenizer.decode([a]) for a in text_tokens]\n",
    "    \n",
    "    # Prepare visualization data\n",
    "    vis_data_records = [\n",
    "        visualization.VisualizationDataRecord(\n",
    "            text_scores, 0, 0, 0, 0, 0, text_tokens_decoded, 1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Generate HTML visualization\n",
    "    html_content = visualization.visualize_text(vis_data_records).data\n",
    "    \n",
    "    # Save to an HTML file\n",
    "    with open(output_html, \"w\", encoding=\"utf-8\") as html_file:\n",
    "        html_file.write(html_content)\n",
    "    print(f\"Heatmap saved to {output_html}\")\n",
    "# Example usage:\n",
    "# Assuming you have the necessary tokenizer and data ready:\n",
    "# show_heatmap_on_text(text, text_encoding, R_text, tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Attribution Scores: tensor([0.4701, 0.2135, 0.2023, 0.2421, 0.1625, 0.0941, 0.0822, 0.3652, 0.0760,\n",
      "        0.1068, 0.0801, 0.1187, 0.2675, 0.1584, 0.0425, 0.4665, 0.2370, 0.6317],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Normalized and Amplified Scores: tensor([0.7257, 0.2902, 0.2713, 0.3388, 0.2037, 0.0877, 0.0674, 0.5477, 0.0569,\n",
      "        0.1093, 0.0638, 0.1293, 0.3820, 0.1968, 0.0000, 0.7197, 0.3301, 1.0000],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Masked Scores (Top-5 Only): tensor([0.4701, 0.0000, 0.0000, 0.2421, 0.0000, 0.0000, 0.0000, 0.3652, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.2675, 0.0000, 0.0000, 0.4665, 0.2370, 0.6317],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "Column 0: Token = Ġresident, Normalized Max Attribution = 0.47009131274221294\n",
      "Column 1: Token = The, Normalized Max Attribution = 0.0\n",
      "Column 2: Token = Ġwealthiest, Normalized Max Attribution = 0.0\n",
      "Column 3: Token = Ġis, Normalized Max Attribution = 0.24207751276396713\n",
      "Column 4: Token = Ġsurvey, Normalized Max Attribution = 0.0\n",
      "Column 5: Token = ĠRich, Normalized Max Attribution = 0.0\n",
      "Column 6: Token = Ġpeople, Normalized Max Attribution = 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>0 (0.00)</b></text></td><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>0.00</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> The                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  BR                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> W                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  Rich                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  200                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  2014                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  the                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  31                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> st                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  annual                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  survey                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  wealthiest                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  people                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  resident                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heatmap saved to heatmap_visualization.html\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Calculate attribution scores\n",
    "attribution_scores = torch.stack([d['optimal_transport'] for d in attributions])\n",
    "print(\"Original Attribution Scores:\", attribution_scores)\n",
    "\n",
    "# Normalize the scores using min-max normalization\n",
    "min_scores = attribution_scores.min(dim=0, keepdim=True).values\n",
    "max_scores = attribution_scores.max(dim=0, keepdim=True).values\n",
    "normalized_scores = (attribution_scores - min_scores) / (max_scores - min_scores + 1e-8)\n",
    "\n",
    "# Optionally, amplify differences (e.g., squaring)\n",
    "amplified_scores = normalized_scores\n",
    "print(\"Normalized and Amplified Scores:\", amplified_scores)\n",
    "\n",
    "# Retain only the top-5 scores and set others to 0\n",
    "top_k = 7\n",
    "values, indices = torch.topk(attribution_scores, k=top_k, dim=0)  # Get top-k scores and indices\n",
    "\n",
    "# Create a mask to set others to 0\n",
    "mask = torch.zeros_like(amplified_scores)\n",
    "mask.scatter_(0, indices, values)  # Place top-k values in the mask\n",
    "masked_scores = mask  # This now contains only the top-k scores\n",
    "print(\"Masked Scores (Top-5 Only):\", masked_scores)\n",
    "\n",
    "# Convert token IDs to token strings\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs.input_ids[0])\n",
    "\n",
    "# Find the corresponding tokens and normalized values\n",
    "result = [(tokens[idx.item()], masked_scores[i].item()) for i, idx in enumerate(indices)]\n",
    "\n",
    "# Print results\n",
    "for i, (token, score) in enumerate(result):\n",
    "    print(f\"Column {i}: Token = {token}, Normalized Max Attribution = {score}\")\n",
    "\n",
    "# Visualize heatmap on text with masked scores\n",
    "show_heatmap_on_text(input_text, inputs.input_ids, masked_scores)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
